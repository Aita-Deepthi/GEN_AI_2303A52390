{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLWbAl/JiE2dTRFOEhhO4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aita-Deepthi/GEN_AI_2303A52390/blob/main/2303A52390_GenAI_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "_cfb0tnnaDXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDwNULACaCpe"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "x=sp.symbols('x')\n",
        "f = 5*x**4 + 3*x**2 + 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(f_str, initial_x, learning_rate, num_iterations):\n",
        "    x = sp.symbols('x')\n",
        "    f_expr = sp.sympify(f_str)\n",
        "    gradient_fn = sp.diff(f_expr, x)\n",
        "    xi = initial_x\n",
        "    for i in range(num_iterations):\n",
        "        gradient = gradient_fn.subs(x, xi)\n",
        "        xi = xi - learning_rate * gradient\n",
        "        if abs(gradient) < 1e-6:\n",
        "            print(f\"Converged at iteration {i+1}\")\n",
        "            break\n",
        "    return xi.evalf(), f_expr.subs(x, xi).evalf()"
      ],
      "metadata": {
        "id": "lS0hRTLSaKY5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = 5*x**4 + 3*x**2 + 10\n",
        "f_str = input(\"Enter the equation: \")\n",
        "initial_x= int(input(\"Enter the initial value of x: \"))\n",
        "learning_rate= float(input(\"Enter the learning rate: \"))\n",
        "num_iterations= int(input(\"Enter the number of iterations: \"))\n",
        "x,min=gradient_descent(f_str,initial_x, learning_rate, num_iterations)\n",
        "\n",
        "print(f\"The function f(x) = {f_str} achieves its minimum value at x = {x}.\")\n",
        "print(f\"At this point, the minimum value of the function is {min}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdF5lHEuaNIb",
        "outputId": "0d393977-f506-46ba-ce87-c8c19717f051"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the equation: 5*x**4 + 3*x**2 + 10\n",
            "Enter the initial value of x: 2\n",
            "Enter the learning rate: 0.01\n",
            "Enter the number of iterations: 150\n",
            "The function f(x) = 5*x**4 + 3*x**2 + 10 achieves its minimum value at x = 0.0000244276389904536.\n",
            "At this point, the minimum value of the function is 10.0000000017901.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "x=sp.symbols('x')\n",
        "f = 5*x**4 + 3*x**2 + 10\n",
        "derivative = sp.diff(f,x)\n",
        "print(\"Differentiate of Function\")\n",
        "derivative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "fnRsRbdvaPvF",
        "outputId": "eec546d7-8494-4716-df0e-9be3fd17ce44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differentiate of Function\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20*x**3 + 6*x"
            ],
            "text/latex": "$\\displaystyle 20 x^{3} + 6 x$"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_2d(f_str, initial_x, initial_y, learning_rate, num_iterations):\n",
        "\n",
        "    x, y = sp.symbols('x y')\n",
        "    f_expr = sp.sympify(f_str)\n",
        "    gradient_x = sp.diff(f_expr, x)\n",
        "    gradient_y = sp.diff(f_expr, y)\n",
        "    xi, yi = initial_x, initial_y\n",
        "    for i in range(num_iterations):\n",
        "        grad_x = gradient_x.subs({x: xi, y: yi})\n",
        "        grad_y = gradient_y.subs({x: xi, y: yi})\n",
        "        xi = xi - learning_rate * grad_x\n",
        "        yi = yi - learning_rate * grad_y\n",
        "        if abs(grad_x) < 1e-6 and abs(grad_y) < 1e-6:\n",
        "            print(f\"Converged at iteration {i+1}\")\n",
        "            break\n",
        "    return xi.evalf(), yi.evalf(), f_expr.subs({x: xi, y: yi}).evalf()"
      ],
      "metadata": {
        "id": "wwoDQOHRaTuj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_str = \"3*x**2 + 5*exp(-y) + 10\"\n",
        "initial_x = float(input(\"Enter the initial value of x : \"))\n",
        "initial_y = float(input(\"Enter the initial value of y : \"))\n",
        "learning_rate = float(input(\"Enter the learning rate : \"))\n",
        "num_iterations = int(input(\"Enter the number of iterations : \"))\n",
        "\n",
        "x_min, y_min, min_value = gradient_descent_2d(f_str, initial_x, initial_y, learning_rate, num_iterations)\n",
        "\n",
        "print(f\"Minimum value of g(x, y) is {min_value} at x = {x_min}, y = {y_min}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkPPji_IaU4P",
        "outputId": "45cd2fdb-a309-4e9c-f8c5-2bea0c8ee4ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the initial value of x : 1\n",
            "Enter the initial value of y : 1\n",
            "Enter the learning rate : 0.01\n",
            "Enter the number of iterations : 150\n",
            "Minimum value of g(x, y) is 10.4877296623691 at x = 0.0000931489663391464, y = 2.32743196298675.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_sigmoid(initial_x, learning_rate, num_iterations):\n",
        "    x = sp.symbols('x')\n",
        "    function = 1 / (1 + sp.exp(-x))\n",
        "    gradient_fn = sp.diff(function, x)\n",
        "    xi = initial_x\n",
        "    for i in range(num_iterations):\n",
        "        gradient = gradient_fn.subs(x, xi)\n",
        "        xi = xi - learning_rate * gradient\n",
        "        if abs(gradient) < 1e-6:\n",
        "            print(f\"Converged at iteration {i+1}\")\n",
        "            break\n",
        "    return xi.evalf(), function.subs(x, xi).evalf()"
      ],
      "metadata": {
        "id": "9YjtdNRcaX3Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_x = float(input(\"Enter the initial value of x : \"))\n",
        "learning_rate = float(input(\"Enter the learning rate : \"))\n",
        "num_iterations = int(input(\"Enter the number of iterations : \"))\n",
        "\n",
        "x_min, min_value = gradient_descent_sigmoid(initial_x, learning_rate, num_iterations)\n",
        "\n",
        "print(f\"Minimum value of z(x) is {min_value} at x = {x_min}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TVpOivTaaXw",
        "outputId": "be981773-c113-40f7-b9d5-da854328c773"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the initial value of x : 2\n",
            "Enter the learning rate : 0.01\n",
            "Enter the number of iterations : 150\n",
            "Minimum value of z(x) is 0.862057374914158 at x = 1.83248399021647.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_linear_model(inputs, expected_outputs, learning_rate, num_iterations):\n",
        "    M, C = 0, 0\n",
        "    n = len(inputs)\n",
        "    for i in range(num_iterations):\n",
        "        gradient_M = sum(-2 * x * (y - (M * x + C)) for x, y in zip(inputs, expected_outputs)) / n\n",
        "        gradient_C = sum(-2 * (y - (M * x + C)) for x, y in zip(inputs, expected_outputs)) / n\n",
        "        M = M - learning_rate * gradient_M\n",
        "        C = C - learning_rate * gradient_C\n",
        "        if abs(gradient_M) < 1e-6 and abs(gradient_C) < 1e-6:\n",
        "            print(f\"Converged at iteration {i+1}\")\n",
        "            break\n",
        "\n",
        "    return M, C"
      ],
      "metadata": {
        "id": "3NZrImQ_ad_y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1, 2, 3, 4]\n",
        "expected_outputs = [2, 4, 6, 8]\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "M_opt, C_opt = gradient_descent_linear_model(inputs, expected_outputs, learning_rate, num_iterations)\n",
        "\n",
        "print(f\"Optimal values are M = {M_opt}, C = {C_opt}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be-tyxbwaiZh",
        "outputId": "3ba65f1f-4f18-4c50-b44c-f9c4a1d6f180"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal values are M = 1.9896587550255742, C = 0.030404521305361965.\n"
          ]
        }
      ]
    }
  ]
}